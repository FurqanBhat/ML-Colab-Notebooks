{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPkW7nkVYDk5NnHKJYgUDKK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FurqanBhat/ML-Colab-Notebooks/blob/main/LSTM_%26_Text_Gen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "O_xPu2Z7ByzQ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, TensorDataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTM(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size):\n",
        "    super(LSTM, self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "\n",
        "    self.forget_gate = nn.Linear(input_size + hidden_size, hidden_size)\n",
        "    self.input_gate = nn.Linear(input_size + hidden_size, hidden_size)\n",
        "    self.cell_gate = nn.Linear(input_size + hidden_size, hidden_size)\n",
        "    self.output_gate = nn.Linear(input_size + hidden_size, hidden_size)\n",
        "\n",
        "  def forward(self, input, hidden, cell):\n",
        "    combined = torch.cat((input, hidden), 1)\n",
        "\n",
        "    forget_gate_output = torch.sigmoid(self.forget_gate(combined))\n",
        "    input_gate_output = torch.sigmoid(self.input_gate(combined))\n",
        "    cell_gate_output = torch.tanh(self.cell_gate(combined))\n",
        "    output_gate_output = torch.sigmoid(self.output_gate(combined))\n",
        "\n",
        "    cell = forget_gate_output * cell + input_gate_output * cell_gate_output\n",
        "    hidden = output_gate_output * torch.tanh(cell)\n",
        "\n",
        "    return hidden, cell"
      ],
      "metadata": {
        "id": "_YXxZ2Q9CDK8"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device=torch.device('cuda' if torch.cuda.is_available else 'cpu')"
      ],
      "metadata": {
        "id": "S5qZFXf0zCuy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "c3sdQ2YazCy0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#data loading\n",
        "with open(\"shakespear_1000.txt\", \"r\") as f:\n",
        "    text = f.read()\n",
        "\n",
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "\n",
        "char2idx = {ch: i for i, ch in enumerate(chars)}\n",
        "idx2char = {i: ch for ch, i in char2idx.items()}\n",
        "encoded_text = [char2idx[c] for c in text]\n",
        "\n"
      ],
      "metadata": {
        "id": "gvd4B-nmCDNh"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#seq preparation\n",
        "seq_length = 100\n",
        "inputs, targets = [], []\n",
        "for i in range(0, len(encoded_text) - seq_length):\n",
        "    inputs.append(encoded_text[i:i+seq_length])\n",
        "    targets.append(encoded_text[i+1:i+seq_length+1])\n",
        "\n",
        "input_tensor = torch.tensor(inputs, dtype=torch.long)\n",
        "target_tensor = torch.tensor(targets, dtype=torch.long)\n",
        "\n",
        "dataset = TensorDataset(input_tensor, target_tensor)\n",
        "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n"
      ],
      "metadata": {
        "id": "KmiLmingCDP7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0590d5d6-fb41-42fa-f8a3-b776462d41fa"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[29, 43, 36, 55, 4, 1, 51, 50, 50, 53, 1, 38, 50, 49, 55, 40, 48, 51, 55, 4, 1, 50, 53, 1, 38, 47, 36, 44, 48, 3, 39, 1, 55, 43, 50, 56, 1, 54, 47, 40, 51, 55, 1, 54, 50, 1, 41, 36, 44, 55, 43, 41, 56, 47, 4, 0, 18, 1, 48, 36, 60, 1, 38, 50, 49, 55, 53, 44, 57, 40, 1, 50, 56, 53, 1, 41, 36, 55, 43, 40, 53, 8, 1, 36, 49, 39, 4, 1, 44, 49, 1, 55, 43, 40, 44, 53, 1, 39, 40, 41], [43, 36, 55, 4, 1, 51, 50, 50, 53, 1, 38, 50, 49, 55, 40, 48, 51, 55, 4, 1, 50, 53, 1, 38, 47, 36, 44, 48, 3, 39, 1, 55, 43, 50, 56, 1, 54, 47, 40, 51, 55, 1, 54, 50, 1, 41, 36, 44, 55, 43, 41, 56, 47, 4, 0, 18, 1, 48, 36, 60, 1, 38, 50, 49, 55, 53, 44, 57, 40, 1, 50, 56, 53, 1, 41, 36, 55, 43, 40, 53, 8, 1, 36, 49, 39, 4, 1, 44, 49, 1, 55, 43, 40, 44, 53, 1, 39, 40, 41, 40], [36, 55, 4, 1, 51, 50, 50, 53, 1, 38, 50, 49, 55, 40, 48, 51, 55, 4, 1, 50, 53, 1, 38, 47, 36, 44, 48, 3, 39, 1, 55, 43, 50, 56, 1, 54, 47, 40, 51, 55, 1, 54, 50, 1, 41, 36, 44, 55, 43, 41, 56, 47, 4, 0, 18, 1, 48, 36, 60, 1, 38, 50, 49, 55, 53, 44, 57, 40, 1, 50, 56, 53, 1, 41, 36, 55, 43, 40, 53, 8, 1, 36, 49, 39, 4, 1, 44, 49, 1, 55, 43, 40, 44, 53, 1, 39, 40, 41, 40, 36], [55, 4, 1, 51, 50, 50, 53, 1, 38, 50, 49, 55, 40, 48, 51, 55, 4, 1, 50, 53, 1, 38, 47, 36, 44, 48, 3, 39, 1, 55, 43, 50, 56, 1, 54, 47, 40, 51, 55, 1, 54, 50, 1, 41, 36, 44, 55, 43, 41, 56, 47, 4, 0, 18, 1, 48, 36, 60, 1, 38, 50, 49, 55, 53, 44, 57, 40, 1, 50, 56, 53, 1, 41, 36, 55, 43, 40, 53, 8, 1, 36, 49, 39, 4, 1, 44, 49, 1, 55, 43, 40, 44, 53, 1, 39, 40, 41, 40, 36, 55]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ShakespeareGenerator(nn.Module):\n",
        "    def __init__(self, vocab_size, input_size, hidden_size):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, input_size)\n",
        "        self.lstm = LSTM(input_size, hidden_size)  # Your custom LSTM cell\n",
        "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
        "\n",
        "    def forward(self, x, h, c):\n",
        "        batch_size, seq_len = x.shape\n",
        "        outputs = []\n",
        "\n",
        "        for t in range(seq_len):\n",
        "            embedded = self.embedding(x[:, t])\n",
        "            h, c = self.lstm(embedded, h, c)\n",
        "            logits = self.fc(h)\n",
        "            outputs.append(logits)\n",
        "\n",
        "        return torch.stack(outputs, dim=1), h, c"
      ],
      "metadata": {
        "id": "qtVtyVYc_JSR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Hyperparameters & Setup ===\n",
        "input_size = 128\n",
        "hidden_size = 256\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = ShakespeareGenerator(vocab_size, input_size, hidden_size).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.002)\n",
        "loss_fn = nn.CrossEntropyLoss()\n"
      ],
      "metadata": {
        "id": "B4Q0_9VbjgDe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# === Training Loop ===\n",
        "for epoch in range(5):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for x_batch, y_batch in dataloader:\n",
        "        x_batch = x_batch.to(device)\n",
        "        y_batch = y_batch.to(device)\n",
        "\n",
        "        h = torch.zeros(x_batch.size(0), hidden_size).to(device)\n",
        "        c = torch.zeros(x_batch.size(0), hidden_size).to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output, _, _ = model(x_batch, h, c)\n",
        "        loss = loss_fn(output.view(-1, vocab_size), y_batch.view(-1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {total_loss / len(dataloader):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_5s1yQTyP0T",
        "outputId": "81d22963-6eab-482d-b7d2-b4496406f0fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.0802\n",
            "Epoch 2, Loss: 0.0795\n",
            "Epoch 3, Loss: 0.0788\n",
            "Epoch 4, Loss: 0.0775\n",
            "Epoch 5, Loss: 0.0771\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "UXZSsiNVyPxg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.save(model.state_dict(), './model.pth') # Save the model's state_dict to a file named 'model.pth' in the current directory."
      ],
      "metadata": {
        "id": "T_dmwVumyP2-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(model, start_text, char2idx, idx2char, length=100, device='cuda'):\n",
        "    \"\"\"\n",
        "    Generates text using the trained ShakespeareGenerator model.\n",
        "\n",
        "    Args:\n",
        "        model: The trained ShakespeareGenerator model.\n",
        "        start_text: The initial text to start generation from.\n",
        "        char2idx: A dictionary mapping characters to their indices.\n",
        "        idx2char: A dictionary mapping indices to their characters.\n",
        "        length: The desired length of the generated text.\n",
        "        device: The device to run the model on (default: 'cuda').\n",
        "\n",
        "    Returns:\n",
        "        The generated text.\n",
        "    \"\"\"\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    # Create input tensor and move it to the specified device\n",
        "    input = torch.tensor([[char2idx[c] for c in start_text]], device=device)\n",
        "    # Create hidden and cell state tensors and move them to the specified device\n",
        "    h = torch.zeros(1, model.lstm.hidden_size, device=device)\n",
        "    c = torch.zeros(1, model.lstm.hidden_size, device=device)\n",
        "\n",
        "    result = start_text\n",
        "\n",
        "    for _ in range(length):\n",
        "        out, h, c = model(input, h, c)\n",
        "        last_logits = out[0, -1]\n",
        "        probs = torch.softmax(last_logits, dim=0)\n",
        "        next_char_idx = torch.multinomial(probs, 1).item()\n",
        "        result += idx2char[next_char_idx]\n",
        "        # Create input tensor for the next character and move it to the specified device\n",
        "        input = torch.tensor([[next_char_idx]], device=device)\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "id": "VM_jVuxSyP5h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(generate(model, \"End\", char2idx, idx2char, length=500))"
      ],
      "metadata": {
        "id": "Z_KB26AkyfNZ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YYOfoR33yfQ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3OX7RmEpyfTq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}