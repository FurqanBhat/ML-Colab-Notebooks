{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP78MdkaSYEBsbAFKWPbQpJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FurqanBhat/ML-Colab-Notebooks/blob/main/spam_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spam = [\n",
        "    \"To use your credit, click the new WAP link in the next years txt message or click here\",\n",
        "    \"Thanks for your subscription to New Ringtone UK your new mobile will be charged £5/month Please confirm annoncement by replying\",\n",
        "    \"As a valued customer, I am pleased to advise you that following recent delivery waiting review of your Mob No. you are awarded with. Call us to review.\",\n",
        "    \"Please call our new customer service representative on\",\n",
        "    \"We are trying to contact you. Last weekends customer draw shows that you won a £1000 prize GUARANTEED. Calling years\",\n",
        "]"
      ],
      "metadata": {
        "id": "x_Ue21VZB_ja"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FOR TESTING\n",
        "spam_test = [\"Customer service annoncement. You have a New Years delivery waiting for you. click\"]\n"
      ],
      "metadata": {
        "id": "cGJjmZxTB_mQ"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "non = [\n",
        "    \"I don't think he goes to usf, he lives around here though\",\n",
        "    \"New car and house for my parents. i have only new job in hand\",\n",
        "    \"Great escape. I fancy the bridge but needs her lager. See you tomorrow\",\n",
        "    \"Tired. I haven't slept well the past few nights.\",\n",
        "    \"Too late. I said i have the website. I didn't i have or dont have the slippers\",\n",
        "    \"I might come by tonight then if my class lets out early\",\n",
        "    \"Jos ask if u wana meet up?\",\n",
        "    \"That would be great. We'll be at the Guild. We can try meeting with the customer on Bristol road or somewhere\"\n",
        "    ]"
      ],
      "metadata": {
        "id": "Ha5u9FyfB_pN"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NON SPAM SENTENCE FOR TESTING\n",
        "spam_test_2 = [\"That would be great. We'll be at the Guild. We can try meeting with the customer on Bristol road or somewhere\"]"
      ],
      "metadata": {
        "id": "v6CmqzI0B_sJ"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.parsing.preprocessing import remove_stopwords\n",
        "from gensim.parsing.porter import PorterStemmer\n",
        "from gensim.utils import tokenize"
      ],
      "metadata": {
        "id": "1EZTxM5ID0WD"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_sentence(sentence):\n",
        "    p = PorterStemmer()\n",
        "    removed_stops = remove_stopwords(sentence)\n",
        "    stemmed = p.stem(removed_stops)\n",
        "    tokens = tokenize(stemmed)\n",
        "    return list(tokens)"
      ],
      "metadata": {
        "id": "WDvPKdJcD0a7"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dictionary = set()     # will have unique values only\n",
        "spams_tokenized = []\n",
        "nons_tokenized = []\n",
        "\n",
        "\n",
        "for sentence in spam:\n",
        "    sentence_tokens = tokenize_sentence(sentence)\n",
        "    spams_tokenized.append(sentence_tokens)\n",
        "    dictionary  = dictionary.union(sentence_tokens)   # add sentence words to the dictionary\n",
        "\n",
        "\n",
        "\n",
        "for sentence in non:\n",
        "    sentence_tokens = tokenize_sentence(sentence)\n",
        "    nons_tokenized.append(sentence_tokens)\n",
        "    dictionary  = dictionary.union(sentence_tokens)\n",
        "\n",
        "\n",
        "\n",
        "print(\"Tokenized spam: \", spams_tokenized)\n",
        "print(\"Tokenized non:  \", nons_tokenized)\n",
        "print(\"Dictionary:     \", dictionary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y24JFWNFD0dP",
        "outputId": "af84d689-958d-46d4-9c06-b4b80fa0c271"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenized spam:  [['to', 'use', 'credit', 'click', 'new', 'wap', 'link', 'years', 'txt', 'message', 'click'], ['thanks', 'subscription', 'new', 'ringtone', 'uk', 'new', 'mobile', 'charged', 'month', 'please', 'confirm', 'annoncement', 'repli'], ['as', 'valued', 'customer', 'i', 'pleased', 'advise', 'following', 'recent', 'delivery', 'waiting', 'review', 'mob', 'no', 'awarded', 'with', 'call', 'review'], ['please', 'new', 'customer', 'service', 'repres'], ['we', 'trying', 'contact', 'you', 'last', 'weekends', 'customer', 'draw', 'shows', 'won', 'prize', 'guaranteed', 'calling', 'year']]\n",
            "Tokenized non:   [['i', 'don', 't', 'think', 'goes', 'usf', 'l'], ['new', 'car', 'house', 'parents', 'new', 'job', 'hand'], ['great', 'escape', 'i', 'fancy', 'bridge', 'needs', 'lager', 'see', 'tomorrow'], ['tired', 'i', 'haven', 't', 'slept', 'past', 'nights'], ['too', 'late', 'i', 'said', 'website', 'i', 'didn', 't', 'dont', 'slipp'], ['i', 'come', 'tonight', 'class', 'lets', 'earli'], ['jos', 'ask', 'u', 'wana', 'meet', 'up'], ['that', 'great', 'we', 'll', 'guild', 'we', 'try', 'meeting', 'customer', 'bristol', 'road']]\n",
            "Dictionary:      {'too', 'meeting', 'parents', 'as', 'haven', 'didn', 'years', 'guaranteed', 'we', 'customer', 'year', 'repres', 'you', 'with', 'mobile', 'that', 'credit', 'contact', 'said', 'car', 'review', 'tomorrow', 'tired', 'bristol', 'please', 'weekends', 'see', 't', 'lager', 'goes', 'wana', 'repli', 'road', 'confirm', 'shows', 'come', 'class', 'last', 'link', 'call', 'website', 'don', 'late', 'thanks', 'draw', 'recent', 'txt', 'won', 'house', 'pleased', 'annoncement', 'u', 'calling', 'service', 'message', 'mob', 'ringtone', 'ask', 'try', 'uk', 'usf', 'nights', 'slept', 'great', 'awarded', 'subscription', 'charged', 'prize', 'tonight', 'hand', 'earli', 'valued', 'past', 'following', 'no', 'guild', 'job', 'use', 'fancy', 'trying', 'dont', 'escape', 'wap', 'delivery', 'waiting', 'up', 'slipp', 'new', 'month', 'i', 'to', 'bridge', 'lets', 'advise', 'meet', 'needs', 'click', 'jos', 'think', 'll', 'l'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# These things do not depend on an individual word so let's calculate them separately once\n",
        "\n",
        "total_word_count = len(dictionary)\n",
        "total_spam_messages = len(spams_tokenized)\n",
        "total_all_messages = len(spams_tokenized) + len(nons_tokenized)\n",
        "\n",
        "print(\"Total Number of words: \", total_word_count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dSpltdi8B_xp",
        "outputId": "ef03c2c4-70e3-471f-f4ae-889f96b7fc3c"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Number of words:  101\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# P(spam) ... does not depend on an individual word so let's calculate that separately once\n",
        "\n",
        "p_spam = total_spam_messages / total_all_messages\n",
        "\n",
        "print(\"P(spam) = \", p_spam)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1fNvGFr5EBKG",
        "outputId": "923f26d9-f2e2-4433-8410-6d2a461e2d1c"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "P(spam) =  0.38461538461538464\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper function to count occurances\n",
        "\n",
        "def count_word_in_messages(word, messages):\n",
        "    total_count = 0\n",
        "    for msg in messages:\n",
        "        if word in msg:       # notice this ensured uniqueness automatically\n",
        "            total_count += 1\n",
        "\n",
        "    return total_count"
      ],
      "metadata": {
        "id": "U9ZCK2UzEBMl"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_prob = 1   # can't start from 0\n",
        "\n",
        "\n",
        "for test_sentence in spam_test:\n",
        "    test_sentence = tokenize_sentence(test_sentence)\n",
        "    print(test_sentence)\n",
        "\n",
        "    # let's run this for each word separately\n",
        "    for word in test_sentence:\n",
        "        print(\"----------------\")\n",
        "        print(\"Runnig for word:\", word)\n",
        "\n",
        "        # Find P( w | spam)\n",
        "        spam_count = count_word_in_messages(word, spams_tokenized)\n",
        "        p_w_spam = spam_count / total_spam_messages\n",
        "        print(\"P( w | spam)  = \", p_w_spam)\n",
        "\n",
        "        # Find P( w )\n",
        "        w_count = count_word_in_messages(word, spams_tokenized)\n",
        "        w_count += count_word_in_messages(word, nons_tokenized)\n",
        "        p_w = w_count / total_all_messages\n",
        "        print(\"P( w )        = \", p_w)\n",
        "\n",
        "\n",
        "        # Find P( spam | w )\n",
        "        p_spam_w = (p_w_spam * p_spam) / p_w\n",
        "        print(\"P( spam )     = \", p_spam)\n",
        "        print(\"P( spam | w ) = \", p_spam_w)\n",
        "        print(\"\")\n",
        "        final_prob *= p_spam_w\n",
        "\n",
        "\n",
        "    print(\"P( spam | all_words ) = \", final_prob)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OCtiX28xEBPq",
        "outputId": "0bda436c-b573-4989-c232-de5a4b750a37"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['customer', 'service', 'annoncement', 'you', 'new', 'years', 'delivery', 'waiting', 'you', 'click']\n",
            "----------------\n",
            "Runnig for word: customer\n",
            "P( w | spam)  =  0.6\n",
            "P( w )        =  0.3076923076923077\n",
            "P( spam )     =  0.38461538461538464\n",
            "P( spam | w ) =  0.75\n",
            "\n",
            "----------------\n",
            "Runnig for word: service\n",
            "P( w | spam)  =  0.2\n",
            "P( w )        =  0.07692307692307693\n",
            "P( spam )     =  0.38461538461538464\n",
            "P( spam | w ) =  1.0\n",
            "\n",
            "----------------\n",
            "Runnig for word: annoncement\n",
            "P( w | spam)  =  0.2\n",
            "P( w )        =  0.07692307692307693\n",
            "P( spam )     =  0.38461538461538464\n",
            "P( spam | w ) =  1.0\n",
            "\n",
            "----------------\n",
            "Runnig for word: you\n",
            "P( w | spam)  =  0.2\n",
            "P( w )        =  0.07692307692307693\n",
            "P( spam )     =  0.38461538461538464\n",
            "P( spam | w ) =  1.0\n",
            "\n",
            "----------------\n",
            "Runnig for word: new\n",
            "P( w | spam)  =  0.6\n",
            "P( w )        =  0.3076923076923077\n",
            "P( spam )     =  0.38461538461538464\n",
            "P( spam | w ) =  0.75\n",
            "\n",
            "----------------\n",
            "Runnig for word: years\n",
            "P( w | spam)  =  0.2\n",
            "P( w )        =  0.07692307692307693\n",
            "P( spam )     =  0.38461538461538464\n",
            "P( spam | w ) =  1.0\n",
            "\n",
            "----------------\n",
            "Runnig for word: delivery\n",
            "P( w | spam)  =  0.2\n",
            "P( w )        =  0.07692307692307693\n",
            "P( spam )     =  0.38461538461538464\n",
            "P( spam | w ) =  1.0\n",
            "\n",
            "----------------\n",
            "Runnig for word: waiting\n",
            "P( w | spam)  =  0.2\n",
            "P( w )        =  0.07692307692307693\n",
            "P( spam )     =  0.38461538461538464\n",
            "P( spam | w ) =  1.0\n",
            "\n",
            "----------------\n",
            "Runnig for word: you\n",
            "P( w | spam)  =  0.2\n",
            "P( w )        =  0.07692307692307693\n",
            "P( spam )     =  0.38461538461538464\n",
            "P( spam | w ) =  1.0\n",
            "\n",
            "----------------\n",
            "Runnig for word: click\n",
            "P( w | spam)  =  0.2\n",
            "P( w )        =  0.07692307692307693\n",
            "P( spam )     =  0.38461538461538464\n",
            "P( spam | w ) =  1.0\n",
            "\n",
            "P( spam | all_words ) =  0.5625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J8QbfHiAEBSZ"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aDgmeK-pB_z5"
      },
      "execution_count": 59,
      "outputs": []
    }
  ]
}